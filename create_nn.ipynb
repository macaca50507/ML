{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_test = '''\\\n",
    "name: \"hw2\"\n",
    "layer {\n",
    "  name: \"YaleB\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"./train_lmdb\"\n",
    "    batch_size: 10\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"YaleB\"\n",
    "  type: \"Data\"\n",
    "  top: \"data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  data_param {\n",
    "    source: \"./test_lmdb\"\n",
    "    batch_size: 10\n",
    "    backend: LMDB\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"fc1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"data\"\n",
    "  top: \"fc1\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 50\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"fc2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"fc1\"\n",
    "  top: \"fc2\"\n",
    "  param {\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 38\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"accuracy\"\n",
    "  type: \"Accuracy\"\n",
    "  bottom: \"fc2\"\n",
    "  bottom: \"label\"\n",
    "  top: \"accuracy\"\n",
    "}\n",
    "layer {\n",
    "  name: \"loss\"\n",
    "  type: \"SoftmaxWithLoss\"\n",
    "  bottom: \"fc2\"\n",
    "  bottom: \"label\"\n",
    "  top: \"loss\"\n",
    "}\n",
    "'''\n",
    "\n",
    "with open('./train_test.prototxt', 'w') as f:\n",
    "    f.write(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "solver = '''\\\n",
    "net: \"./train_test.prototxt\"\n",
    "test_iter: 100\n",
    "test_interval: 1000\n",
    "base_lr: 0.001\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "lr_policy: \"inv\"\n",
    "gamma: 0.0001\n",
    "power: 0.75\n",
    "display: 100\n",
    "max_iter: 2000\n",
    "snapshot: 5000\n",
    "snapshot_prefix: \"./snapshot\"\n",
    "solver_mode: CPU\n",
    "'''\n",
    "\n",
    "with open('./solver.prototxt', 'w') as f:\n",
    "    f.write(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "solver = None\n",
    "solver = caffe.SGDSolver('./solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', (10, 1, 192, 168)),\n",
       " ('label', (10,)),\n",
       " ('label_YaleB_1_split_0', (10,)),\n",
       " ('label_YaleB_1_split_1', (10,)),\n",
       " ('fc1', (10, 50)),\n",
       " ('fc2', (10, 38)),\n",
       " ('fc2_fc2_0_split_0', (10, 38)),\n",
       " ('fc2_fc2_0_split_1', (10, 38)),\n",
       " ('accuracy', ()),\n",
       " ('loss', ())]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.data.shape) for k, v in solver.net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0328 12:19:00.399682   176 caffe.cpp:211] Use CPU.\n",
      "I0328 12:19:00.400455   176 solver.cpp:44] Initializing solver from parameters: \n",
      "test_iter: 100\n",
      "test_interval: 1000\n",
      "base_lr: 0.001\n",
      "display: 100\n",
      "max_iter: 2000\n",
      "lr_policy: \"inv\"\n",
      "gamma: 0.0001\n",
      "power: 0.75\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "snapshot: 5000\n",
      "snapshot_prefix: \"./snapshot\"\n",
      "solver_mode: CPU\n",
      "net: \"./train_test.prototxt\"\n",
      "train_state {\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "I0328 12:19:00.404706   176 solver.cpp:87] Creating training net from net file: ./train_test.prototxt\n",
      "I0328 12:19:00.408532   176 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer YaleB\n",
      "I0328 12:19:00.408870   176 net.cpp:53] Initializing net from parameters: \n",
      "name: \"hw2\"\n",
      "state {\n",
      "  phase: TRAIN\n",
      "  level: 0\n",
      "  stage: \"\"\n",
      "}\n",
      "layer {\n",
      "  name: \"YaleB\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  transform_param {\n",
      "    scale: 0.00390625\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"./train_lmdb\"\n",
      "    batch_size: 10\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"data\"\n",
      "  top: \"fc1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 50\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc1\"\n",
      "  top: \"fc2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 38\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"fc2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0328 12:19:00.409332   176 layer_factory.hpp:77] Creating layer YaleB\n",
      "I0328 12:19:00.453618   176 db_lmdb.cpp:35] Opened lmdb ./train_lmdb\n",
      "I0328 12:19:00.456151   176 net.cpp:86] Creating Layer YaleB\n",
      "I0328 12:19:00.456260   176 net.cpp:382] YaleB -> data\n",
      "I0328 12:19:00.456332   176 net.cpp:382] YaleB -> label\n",
      "I0328 12:19:00.459475   176 data_layer.cpp:45] output data size: 10,1,192,168\n",
      "I0328 12:19:00.459848   176 net.cpp:124] Setting up YaleB\n",
      "I0328 12:19:00.459899   176 net.cpp:131] Top shape: 10 1 192 168 (322560)\n",
      "I0328 12:19:00.459933   176 net.cpp:131] Top shape: 10 (10)\n",
      "I0328 12:19:00.459959   176 net.cpp:139] Memory required for data: 1290280\n",
      "I0328 12:19:00.460001   176 layer_factory.hpp:77] Creating layer label_YaleB_1_split\n",
      "I0328 12:19:00.460055   176 net.cpp:86] Creating Layer label_YaleB_1_split\n",
      "I0328 12:19:00.460091   176 net.cpp:408] label_YaleB_1_split <- label\n",
      "I0328 12:19:00.460137   176 net.cpp:382] label_YaleB_1_split -> label_YaleB_1_split_0\n",
      "I0328 12:19:00.460180   176 net.cpp:382] label_YaleB_1_split -> label_YaleB_1_split_1\n",
      "I0328 12:19:00.460223   176 net.cpp:124] Setting up label_YaleB_1_split\n",
      "I0328 12:19:00.460258   176 net.cpp:131] Top shape: 10 (10)\n",
      "I0328 12:19:00.460288   176 net.cpp:131] Top shape: 10 (10)\n",
      "I0328 12:19:00.460314   176 net.cpp:139] Memory required for data: 1290360\n",
      "I0328 12:19:00.460345   176 layer_factory.hpp:77] Creating layer fc1\n",
      "I0328 12:19:00.460386   176 net.cpp:86] Creating Layer fc1\n",
      "I0328 12:19:00.460417   176 net.cpp:408] fc1 <- data\n",
      "I0328 12:19:00.460464   176 net.cpp:382] fc1 -> fc1\n",
      "I0328 12:19:00.484691   176 net.cpp:124] Setting up fc1\n",
      "I0328 12:19:00.484757   176 net.cpp:131] Top shape: 10 50 (500)\n",
      "I0328 12:19:00.484776   176 net.cpp:139] Memory required for data: 1292360\n",
      "I0328 12:19:00.484818   176 layer_factory.hpp:77] Creating layer fc2\n",
      "I0328 12:19:00.484845   176 net.cpp:86] Creating Layer fc2\n",
      "I0328 12:19:00.484866   176 net.cpp:408] fc2 <- fc1\n",
      "I0328 12:19:00.484886   176 net.cpp:382] fc2 -> fc2\n",
      "I0328 12:19:00.485116   176 net.cpp:124] Setting up fc2\n",
      "I0328 12:19:00.485177   176 net.cpp:131] Top shape: 10 38 (380)\n",
      "I0328 12:19:00.485204   176 net.cpp:139] Memory required for data: 1293880\n",
      "I0328 12:19:00.485244   176 layer_factory.hpp:77] Creating layer fc2_fc2_0_split\n",
      "I0328 12:19:00.485280   176 net.cpp:86] Creating Layer fc2_fc2_0_split\n",
      "I0328 12:19:00.485594   176 net.cpp:408] fc2_fc2_0_split <- fc2\n",
      "I0328 12:19:00.485707   176 net.cpp:382] fc2_fc2_0_split -> fc2_fc2_0_split_0\n",
      "I0328 12:19:00.486003   176 net.cpp:382] fc2_fc2_0_split -> fc2_fc2_0_split_1\n",
      "I0328 12:19:00.486042   176 net.cpp:124] Setting up fc2_fc2_0_split\n",
      "I0328 12:19:00.486083   176 net.cpp:131] Top shape: 10 38 (380)\n",
      "I0328 12:19:00.486377   176 net.cpp:131] Top shape: 10 38 (380)\n",
      "I0328 12:19:00.486403   176 net.cpp:139] Memory required for data: 1296920\n",
      "I0328 12:19:00.486431   176 layer_factory.hpp:77] Creating layer accuracy\n",
      "I0328 12:19:00.486470   176 net.cpp:86] Creating Layer accuracy\n",
      "I0328 12:19:00.486505   176 net.cpp:408] accuracy <- fc2_fc2_0_split_0\n",
      "I0328 12:19:00.486778   176 net.cpp:408] accuracy <- label_YaleB_1_split_0\n",
      "I0328 12:19:00.486815   176 net.cpp:382] accuracy -> accuracy\n",
      "I0328 12:19:00.486860   176 net.cpp:124] Setting up accuracy\n",
      "I0328 12:19:00.487098   176 net.cpp:131] Top shape: (1)\n",
      "I0328 12:19:00.487145   176 net.cpp:139] Memory required for data: 1296924\n",
      "I0328 12:19:00.487174   176 layer_factory.hpp:77] Creating layer loss\n",
      "I0328 12:19:00.487207   176 net.cpp:86] Creating Layer loss\n",
      "I0328 12:19:00.487231   176 net.cpp:408] loss <- fc2_fc2_0_split_1\n",
      "I0328 12:19:00.487459   176 net.cpp:408] loss <- label_YaleB_1_split_1\n",
      "I0328 12:19:00.487517   176 net.cpp:382] loss -> loss\n",
      "I0328 12:19:00.487562   176 layer_factory.hpp:77] Creating layer loss\n",
      "I0328 12:19:00.487893   176 net.cpp:124] Setting up loss\n",
      "I0328 12:19:00.487952   176 net.cpp:131] Top shape: (1)\n",
      "I0328 12:19:00.487999   176 net.cpp:134]     with loss weight 1\n",
      "I0328 12:19:00.488281   176 net.cpp:139] Memory required for data: 1296928\n",
      "I0328 12:19:00.488312   176 net.cpp:200] loss needs backward computation.\n",
      "I0328 12:19:00.488349   176 net.cpp:202] accuracy does not need backward computation.\n",
      "I0328 12:19:00.488620   176 net.cpp:200] fc2_fc2_0_split needs backward computation.\n",
      "I0328 12:19:00.488662   176 net.cpp:200] fc2 needs backward computation.\n",
      "I0328 12:19:00.488690   176 net.cpp:200] fc1 needs backward computation.\n",
      "I0328 12:19:00.488927   176 net.cpp:202] label_YaleB_1_split does not need backward computation.\n",
      "I0328 12:19:00.488966   176 net.cpp:202] YaleB does not need backward computation.\n",
      "I0328 12:19:00.488999   176 net.cpp:244] This network produces output accuracy\n",
      "I0328 12:19:00.489035   176 net.cpp:244] This network produces output loss\n",
      "I0328 12:19:00.489230   176 net.cpp:257] Network initialization done.\n",
      "I0328 12:19:00.495797   176 solver.cpp:173] Creating test net (#0) specified by net file: ./train_test.prototxt\n",
      "I0328 12:19:00.496121   176 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer YaleB\n",
      "I0328 12:19:00.499703   176 net.cpp:53] Initializing net from parameters: \n",
      "name: \"hw2\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"YaleB\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  transform_param {\n",
      "    scale: 0.00390625\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"./test_lmdb\"\n",
      "    batch_size: 10\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc1\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"data\"\n",
      "  top: \"fc1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 50\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc2\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc1\"\n",
      "  top: \"fc2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 38\n",
      "    weight_filler {\n",
      "      type: \"xavier\"\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"fc2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc2\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0328 12:19:00.500700   176 layer_factory.hpp:77] Creating layer YaleB\n",
      "I0328 12:19:00.559607   176 db_lmdb.cpp:35] Opened lmdb ./test_lmdb\n",
      "I0328 12:19:00.562259   176 net.cpp:86] Creating Layer YaleB\n",
      "I0328 12:19:00.562474   176 net.cpp:382] YaleB -> data\n",
      "I0328 12:19:00.562558   176 net.cpp:382] YaleB -> label\n",
      "I0328 12:19:00.567075   176 data_layer.cpp:45] output data size: 10,1,192,168\n",
      "I0328 12:19:00.567966   176 net.cpp:124] Setting up YaleB\n",
      "I0328 12:19:00.568568   176 net.cpp:131] Top shape: 10 1 192 168 (322560)\n",
      "I0328 12:19:00.569303   176 net.cpp:131] Top shape: 10 (10)\n",
      "I0328 12:19:00.569346   176 net.cpp:139] Memory required for data: 1290280\n",
      "I0328 12:19:00.569682   176 layer_factory.hpp:77] Creating layer label_YaleB_1_split\n",
      "I0328 12:19:00.569746   176 net.cpp:86] Creating Layer label_YaleB_1_split\n",
      "I0328 12:19:00.569792   176 net.cpp:408] label_YaleB_1_split <- label\n",
      "I0328 12:19:00.570186   176 net.cpp:382] label_YaleB_1_split -> label_YaleB_1_split_0\n",
      "I0328 12:19:00.570252   176 net.cpp:382] label_YaleB_1_split -> label_YaleB_1_split_1\n",
      "I0328 12:19:00.570318   176 net.cpp:124] Setting up label_YaleB_1_split\n",
      "I0328 12:19:00.571812   176 net.cpp:131] Top shape: 10 (10)\n",
      "I0328 12:19:00.571967   176 net.cpp:131] Top shape: 10 (10)\n",
      "I0328 12:19:00.572011   176 net.cpp:139] Memory required for data: 1290360\n",
      "I0328 12:19:00.572057   176 layer_factory.hpp:77] Creating layer fc1\n",
      "I0328 12:19:00.572132   176 net.cpp:86] Creating Layer fc1\n",
      "I0328 12:19:00.573055   176 net.cpp:408] fc1 <- data\n",
      "I0328 12:19:00.573406   176 net.cpp:382] fc1 -> fc1\n",
      "I0328 12:19:00.612032   176 net.cpp:124] Setting up fc1\n",
      "I0328 12:19:00.612252   176 net.cpp:131] Top shape: 10 50 (500)\n",
      "I0328 12:19:00.612303   176 net.cpp:139] Memory required for data: 1292360\n",
      "I0328 12:19:00.612440   176 layer_factory.hpp:77] Creating layer fc2\n",
      "I0328 12:19:00.612747   176 net.cpp:86] Creating Layer fc2\n",
      "I0328 12:19:00.612788   176 net.cpp:408] fc2 <- fc1\n",
      "I0328 12:19:00.613353   176 net.cpp:382] fc2 -> fc2\n",
      "I0328 12:19:00.613715   176 net.cpp:124] Setting up fc2\n",
      "I0328 12:19:00.613776   176 net.cpp:131] Top shape: 10 38 (380)\n",
      "I0328 12:19:00.613821   176 net.cpp:139] Memory required for data: 1293880\n",
      "I0328 12:19:00.613878   176 layer_factory.hpp:77] Creating layer fc2_fc2_0_split\n",
      "I0328 12:19:00.614174   176 net.cpp:86] Creating Layer fc2_fc2_0_split\n",
      "I0328 12:19:00.614282   176 net.cpp:408] fc2_fc2_0_split <- fc2\n",
      "I0328 12:19:00.614570   176 net.cpp:382] fc2_fc2_0_split -> fc2_fc2_0_split_0\n",
      "I0328 12:19:00.614627   176 net.cpp:382] fc2_fc2_0_split -> fc2_fc2_0_split_1\n",
      "I0328 12:19:00.615340   176 net.cpp:124] Setting up fc2_fc2_0_split\n",
      "I0328 12:19:00.615411   176 net.cpp:131] Top shape: 10 38 (380)\n",
      "I0328 12:19:00.615448   176 net.cpp:131] Top shape: 10 38 (380)\n",
      "I0328 12:19:00.615751   176 net.cpp:139] Memory required for data: 1296920\n",
      "I0328 12:19:00.616441   176 layer_factory.hpp:77] Creating layer accuracy\n",
      "I0328 12:19:00.616510   176 net.cpp:86] Creating Layer accuracy\n",
      "I0328 12:19:00.616549   176 net.cpp:408] accuracy <- fc2_fc2_0_split_0\n",
      "I0328 12:19:00.616816   176 net.cpp:408] accuracy <- label_YaleB_1_split_0\n",
      "I0328 12:19:00.616878   176 net.cpp:382] accuracy -> accuracy\n",
      "I0328 12:19:00.616938   176 net.cpp:124] Setting up accuracy\n",
      "I0328 12:19:00.617218   176 net.cpp:131] Top shape: (1)\n",
      "I0328 12:19:00.617267   176 net.cpp:139] Memory required for data: 1296924\n",
      "I0328 12:19:00.617311   176 layer_factory.hpp:77] Creating layer loss\n",
      "I0328 12:19:00.617370   176 net.cpp:86] Creating Layer loss\n",
      "I0328 12:19:00.617790   176 net.cpp:408] loss <- fc2_fc2_0_split_1\n",
      "I0328 12:19:00.618167   176 net.cpp:408] loss <- label_YaleB_1_split_1\n",
      "I0328 12:19:00.618230   176 net.cpp:382] loss -> loss\n",
      "I0328 12:19:00.618288   176 layer_factory.hpp:77] Creating layer loss\n",
      "I0328 12:19:00.618667   176 net.cpp:124] Setting up loss\n",
      "I0328 12:19:00.618723   176 net.cpp:131] Top shape: (1)\n",
      "I0328 12:19:00.618762   176 net.cpp:134]     with loss weight 1\n",
      "I0328 12:19:00.619113   176 net.cpp:139] Memory required for data: 1296928\n",
      "I0328 12:19:00.619202   176 net.cpp:200] loss needs backward computation.\n",
      "I0328 12:19:00.619549   176 net.cpp:202] accuracy does not need backward computation.\n",
      "I0328 12:19:00.619599   176 net.cpp:200] fc2_fc2_0_split needs backward computation.\n",
      "I0328 12:19:00.619637   176 net.cpp:200] fc2 needs backward computation.\n",
      "I0328 12:19:00.620115   176 net.cpp:200] fc1 needs backward computation.\n",
      "I0328 12:19:00.620687   176 net.cpp:202] label_YaleB_1_split does not need backward computation.\n",
      "I0328 12:19:00.620836   176 net.cpp:202] YaleB does not need backward computation.\n",
      "I0328 12:19:00.621445   176 net.cpp:244] This network produces output accuracy\n",
      "I0328 12:19:00.621495   176 net.cpp:244] This network produces output loss\n",
      "I0328 12:19:00.621870   176 net.cpp:257] Network initialization done.\n",
      "I0328 12:19:00.622285   176 solver.cpp:56] Solver scaffolding done.\n",
      "I0328 12:19:00.622373   176 caffe.cpp:248] Starting Optimization\n",
      "I0328 12:19:00.622747   176 solver.cpp:273] Solving hw2\n",
      "I0328 12:19:00.622794   176 solver.cpp:274] Learning Rate Policy: inv\n",
      "I0328 12:19:00.626518   176 solver.cpp:331] Iteration 0, Testing net (#0)\n",
      "I0328 12:19:00.641419   176 blocking_queue.cpp:49] Waiting for data\n",
      "I0328 12:19:02.212326   176 solver.cpp:398]     Test net output #0: accuracy = 0.021\n",
      "I0328 12:19:02.212487   176 solver.cpp:398]     Test net output #1: loss = 3.67813 (* 1 = 3.67813 loss)\n",
      "I0328 12:19:02.227195   176 solver.cpp:219] Iteration 0 (-3.96096e-38 iter/s, 1.604s/100 iters), loss = 3.74461\n",
      "I0328 12:19:02.227298   176 solver.cpp:238]     Train net output #0: accuracy = 0\n",
      "I0328 12:19:02.227339   176 solver.cpp:238]     Train net output #1: loss = 3.74461 (* 1 = 3.74461 loss)\n",
      "I0328 12:19:02.227406   176 sgd_solver.cpp:105] Iteration 0, lr = 0.001\n",
      "I0328 12:19:05.822497   176 solver.cpp:219] Iteration 100 (27.8164 iter/s, 3.595s/100 iters), loss = 3.138\n",
      "I0328 12:19:05.822592   176 solver.cpp:238]     Train net output #0: accuracy = 0.3\n",
      "I0328 12:19:05.822654   176 solver.cpp:238]     Train net output #1: loss = 3.138 (* 1 = 3.138 loss)\n",
      "I0328 12:19:05.822710   176 sgd_solver.cpp:105] Iteration 100, lr = 0.000992565\n",
      "I0328 12:19:07.385732   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:09.647874   176 solver.cpp:219] Iteration 200 (26.1438 iter/s, 3.825s/100 iters), loss = 3.10689\n",
      "I0328 12:19:09.647999   176 solver.cpp:238]     Train net output #0: accuracy = 0.2\n",
      "I0328 12:19:09.648051   176 solver.cpp:238]     Train net output #1: loss = 3.10689 (* 1 = 3.10689 loss)\n",
      "I0328 12:19:09.648102   176 sgd_solver.cpp:105] Iteration 200, lr = 0.000985258\n",
      "I0328 12:19:11.513741   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:12.668495   176 solver.cpp:219] Iteration 300 (33.1126 iter/s, 3.02s/100 iters), loss = 1.67244\n",
      "I0328 12:19:12.668588   176 solver.cpp:238]     Train net output #0: accuracy = 0.8\n",
      "I0328 12:19:12.668629   176 solver.cpp:238]     Train net output #1: loss = 1.67244 (* 1 = 1.67244 loss)\n",
      "I0328 12:19:12.668725   176 sgd_solver.cpp:105] Iteration 300, lr = 0.000978075\n",
      "I0328 12:19:15.608499   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:15.767134   176 solver.cpp:219] Iteration 400 (32.2789 iter/s, 3.098s/100 iters), loss = 1.13858\n",
      "I0328 12:19:15.767233   176 solver.cpp:238]     Train net output #0: accuracy = 0.8\n",
      "I0328 12:19:15.767266   176 solver.cpp:238]     Train net output #1: loss = 1.13858 (* 1 = 1.13858 loss)\n",
      "I0328 12:19:15.767307   176 sgd_solver.cpp:105] Iteration 400, lr = 0.000971013\n",
      "I0328 12:19:18.669857   176 solver.cpp:219] Iteration 500 (34.459 iter/s, 2.902s/100 iters), loss = 1.14651\n",
      "I0328 12:19:18.669948   176 solver.cpp:238]     Train net output #0: accuracy = 0.8\n",
      "I0328 12:19:18.669993   176 solver.cpp:238]     Train net output #1: loss = 1.14651 (* 1 = 1.14651 loss)\n",
      "I0328 12:19:18.670259   176 sgd_solver.cpp:105] Iteration 500, lr = 0.000964069\n",
      "I0328 12:19:19.519385   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:21.761862   176 solver.cpp:219] Iteration 600 (32.352 iter/s, 3.091s/100 iters), loss = 0.835463\n",
      "I0328 12:19:21.761955   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:21.761994   176 solver.cpp:238]     Train net output #1: loss = 0.835463 (* 1 = 0.835463 loss)\n",
      "I0328 12:19:21.762089   176 sgd_solver.cpp:105] Iteration 600, lr = 0.00095724\n",
      "I0328 12:19:23.556720   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:24.673190   176 solver.cpp:219] Iteration 700 (34.3525 iter/s, 2.911s/100 iters), loss = 0.412253\n",
      "I0328 12:19:24.674089   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:24.674178   176 solver.cpp:238]     Train net output #1: loss = 0.412253 (* 1 = 0.412253 loss)\n",
      "I0328 12:19:24.674233   176 sgd_solver.cpp:105] Iteration 700, lr = 0.000950522\n",
      "I0328 12:19:27.341665   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:27.533380   176 solver.cpp:219] Iteration 800 (34.9773 iter/s, 2.859s/100 iters), loss = 0.888729\n",
      "I0328 12:19:27.533576   176 solver.cpp:238]     Train net output #0: accuracy = 0.8\n",
      "I0328 12:19:27.533614   176 solver.cpp:238]     Train net output #1: loss = 0.888729 (* 1 = 0.888729 loss)\n",
      "I0328 12:19:27.533644   176 sgd_solver.cpp:105] Iteration 800, lr = 0.000943913\n",
      "I0328 12:19:30.432616   176 solver.cpp:219] Iteration 900 (34.4947 iter/s, 2.899s/100 iters), loss = 0.617851\n",
      "I0328 12:19:30.433678   176 solver.cpp:238]     Train net output #0: accuracy = 0.9\n",
      "I0328 12:19:30.433745   176 solver.cpp:238]     Train net output #1: loss = 0.61785 (* 1 = 0.61785 loss)\n",
      "I0328 12:19:30.433789   176 sgd_solver.cpp:105] Iteration 900, lr = 0.000937411\n",
      "I0328 12:19:31.213800   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:33.476076   176 solver.cpp:331] Iteration 1000, Testing net (#0)\n",
      "I0328 12:19:33.534801   179 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:34.103467   176 solver.cpp:398]     Test net output #0: accuracy = 0.493\n",
      "I0328 12:19:34.103658   176 solver.cpp:398]     Test net output #1: loss = 2.13707 (* 1 = 2.13707 loss)\n",
      "I0328 12:19:34.117226   176 solver.cpp:219] Iteration 1000 (27.1518 iter/s, 3.683s/100 iters), loss = 0.361571\n",
      "I0328 12:19:34.117427   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:34.117462   176 solver.cpp:238]     Train net output #1: loss = 0.361571 (* 1 = 0.361571 loss)\n",
      "I0328 12:19:34.117493   176 sgd_solver.cpp:105] Iteration 1000, lr = 0.000931013\n",
      "I0328 12:19:35.909937   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:37.095494   176 solver.cpp:219] Iteration 1100 (33.5796 iter/s, 2.978s/100 iters), loss = 0.458035\n",
      "I0328 12:19:37.095583   176 solver.cpp:238]     Train net output #0: accuracy = 0.9\n",
      "I0328 12:19:37.095609   176 solver.cpp:238]     Train net output #1: loss = 0.458035 (* 1 = 0.458035 loss)\n",
      "I0328 12:19:37.095633   176 sgd_solver.cpp:105] Iteration 1100, lr = 0.000924715\n",
      "I0328 12:19:39.908963   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:40.160210   176 solver.cpp:219] Iteration 1200 (32.6371 iter/s, 3.064s/100 iters), loss = 0.183202\n",
      "I0328 12:19:40.160408   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:40.160482   176 solver.cpp:238]     Train net output #1: loss = 0.183202 (* 1 = 0.183202 loss)\n",
      "I0328 12:19:40.160564   176 sgd_solver.cpp:105] Iteration 1200, lr = 0.000918516\n",
      "I0328 12:19:43.403079   176 solver.cpp:219] Iteration 1300 (30.8452 iter/s, 3.242s/100 iters), loss = 0.653767\n",
      "I0328 12:19:43.403185   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:43.403229   176 solver.cpp:238]     Train net output #1: loss = 0.653767 (* 1 = 0.653767 loss)\n",
      "I0328 12:19:43.403297   176 sgd_solver.cpp:105] Iteration 1300, lr = 0.000912412\n",
      "I0328 12:19:44.120875   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:46.667657   176 solver.cpp:219] Iteration 1400 (30.6373 iter/s, 3.264s/100 iters), loss = 0.224493\n",
      "I0328 12:19:46.667754   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:46.667781   176 solver.cpp:238]     Train net output #1: loss = 0.224493 (* 1 = 0.224493 loss)\n",
      "I0328 12:19:46.667806   176 sgd_solver.cpp:105] Iteration 1400, lr = 0.000906403\n",
      "I0328 12:19:48.998306   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:51.629482   176 solver.cpp:219] Iteration 1500 (20.1572 iter/s, 4.961s/100 iters), loss = 0.110124\n",
      "I0328 12:19:51.629737   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:51.629806   176 solver.cpp:238]     Train net output #1: loss = 0.110124 (* 1 = 0.110124 loss)\n",
      "I0328 12:19:51.629859   176 sgd_solver.cpp:105] Iteration 1500, lr = 0.000900485\n",
      "I0328 12:19:55.807754   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:19:56.139664   176 solver.cpp:219] Iteration 1600 (22.1779 iter/s, 4.509s/100 iters), loss = 0.148759\n",
      "I0328 12:19:56.139955   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:19:56.140038   176 solver.cpp:238]     Train net output #1: loss = 0.148759 (* 1 = 0.148759 loss)\n",
      "I0328 12:19:56.140125   176 sgd_solver.cpp:105] Iteration 1600, lr = 0.000894657\n",
      "I0328 12:20:00.080155   176 solver.cpp:219] Iteration 1700 (25.3807 iter/s, 3.94s/100 iters), loss = 0.154471\n",
      "I0328 12:20:00.080258   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:20:00.080297   176 solver.cpp:238]     Train net output #1: loss = 0.154471 (* 1 = 0.154471 loss)\n",
      "I0328 12:20:00.080528   176 sgd_solver.cpp:105] Iteration 1700, lr = 0.000888916\n",
      "I0328 12:20:01.040940   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:20:03.552232   176 solver.cpp:219] Iteration 1800 (28.8101 iter/s, 3.471s/100 iters), loss = 0.0894594\n",
      "I0328 12:20:03.552325   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:20:03.552367   176 solver.cpp:238]     Train net output #1: loss = 0.0894596 (* 1 = 0.0894596 loss)\n",
      "I0328 12:20:03.552444   176 sgd_solver.cpp:105] Iteration 1800, lr = 0.00088326\n",
      "I0328 12:20:05.958452   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:20:07.525086   176 solver.cpp:219] Iteration 1900 (25.1762 iter/s, 3.972s/100 iters), loss = 0.0949401\n",
      "I0328 12:20:07.525199   176 solver.cpp:238]     Train net output #0: accuracy = 1\n",
      "I0328 12:20:07.525243   176 solver.cpp:238]     Train net output #1: loss = 0.0949403 (* 1 = 0.0949403 loss)\n",
      "I0328 12:20:07.525353   176 sgd_solver.cpp:105] Iteration 1900, lr = 0.000877687\n",
      "I0328 12:20:10.886569   178 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:20:11.167749   176 solver.cpp:448] Snapshotting to binary proto file ./snapshot_iter_2000.caffemodel\n",
      "I0328 12:20:11.598076   176 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshot_iter_2000.solverstate\n",
      "I0328 12:20:12.031747   176 solver.cpp:311] Iteration 2000, loss = 0.0877521\n",
      "I0328 12:20:12.031949   176 solver.cpp:331] Iteration 2000, Testing net (#0)\n",
      "I0328 12:20:12.121314   179 data_layer.cpp:73] Restarting data prefetching from start.\n",
      "I0328 12:20:12.686064   176 solver.cpp:398]     Test net output #0: accuracy = 0.535\n",
      "I0328 12:20:12.686182   176 solver.cpp:398]     Test net output #1: loss = 1.95973 (* 1 = 1.95973 loss)\n",
      "I0328 12:20:12.686213   176 solver.cpp:316] Optimization Done.\n",
      "I0328 12:20:12.686256   176 caffe.cpp:259] Optimization Done.\n"
     ]
    }
   ],
   "source": [
    "!caffe train --solver=./solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing...\n",
      "0.025\n",
      "Iteration 500 testing...\n",
      "0.321\n",
      "Iteration 1000 testing...\n",
      "0.493\n",
      "Iteration 1500 testing...\n",
      "0.518\n",
      "CPU times: user 1min, sys: 940 ms, total: 1min 1s\n",
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "niter = 2000\n",
    "test_interval = 500\n",
    "# losses will also be stored in the log\n",
    "train_loss = zeros(niter)\n",
    "test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "# output = zeros((niter, 8, 38))\n",
    "\n",
    "# the main solver loop\n",
    "for it in range(niter):\n",
    "    solver.step(1)  # SGD by Caffe\n",
    "    \n",
    "    # store the train loss\n",
    "    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    \n",
    "    # store the output on the first test batch\n",
    "    # (start the forward pass at conv1 to avoid loading new data)\n",
    "#     solver.test_nets[0].forward(start='conv1')\n",
    "#     output[it] = solver.test_nets[0].blobs['score'].data[:8]\n",
    "    \n",
    "    # run a full test every so often\n",
    "    # (Caffe can also do this for us and write to a log, but we show here\n",
    "    #  how to do it directly in Python, where more complicated things are easier.)\n",
    "    if it % test_interval == 0:\n",
    "        print 'Iteration', it, 'testing...'\n",
    "        correct = 0\n",
    "        for test_it in range(100):\n",
    "            solver.test_nets[0].forward()\n",
    "            correct += sum(solver.test_nets[0].blobs['fc2'].data.argmax(1)\n",
    "                           == solver.test_nets[0].blobs['label'].data)\n",
    "        test_acc[it // test_interval] = correct / 1000.0\n",
    "        print correct / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f7d45a4ef90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d37347c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax1 = subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(arange(niter), train_loss)\n",
    "ax2.plot(test_interval * arange(len(test_acc)), test_acc, 'r')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('train loss')\n",
    "ax2.set_ylabel('test accuracy')\n",
    "ax2.set_title('Test Accuracy: {:.2f}'.format(test_acc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
